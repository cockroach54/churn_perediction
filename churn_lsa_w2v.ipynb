{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:862: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# CORPUS 만들기\n",
    "from gensim import corpora, models, similarities\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow as tf\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('total3.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc = df.drop(['macaddr', 'y'], axis=1).as_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "doc = np.array(doc, dtype=str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 여기는 LSA model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 날자별로 다른 문서로 만들기위해 리쉐입\n",
    "doc = doc.reshape([-1,24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153790, 24)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary(1054 unique tokens: ['442', '194', '244', '430', '839']...)\n"
     ]
    }
   ],
   "source": [
    "# generate corpus\n",
    "dictionary = corpora.Dictionary(doc)\n",
    "cps = [dictionary.doc2bow(text) for text in doc] # corpus\n",
    "# print(dictionary.token2id)\n",
    "print(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TfidfModel(num_docs=153790, num_nnz=720092)\n"
     ]
    }
   ],
   "source": [
    "# tf-idf tansformation\n",
    "tfidf = models.TfidfModel(cps)\n",
    "cps_tfidf = tfidf[cps] # tfidf로 치환된 sparse vectors\n",
    "print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# LSA/LSI transformation\n",
    "dim = 24\n",
    "lsi = models.LsiModel(cps_tfidf, id2word=dictionary, num_topics=dim)\n",
    "cps_lsi = lsi[cps_tfidf] # num_topic n-dim으로 치환된 코퍼스 \n",
    "\n",
    "# 코퍼스는 메모리 아끼려고 콜할때 완성되므로 미리 매트릭스 만듦\n",
    "mtx_lsi = []\n",
    "for el in cps_lsi:\n",
    "    mtx_lsi.append([v[1] for v in el])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "153790"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(mtx_lsi)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx_lsi2 = np.array(mtx_lsi).reshape([-1,26*24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_lsi = pd.DataFrame(mtx_lsi2, columns=['lsi%d'%idx for idx in range(mtx_lsi2.shape[1])])\n",
    "df_lsi = pd.concat([df['macaddr'], df_lsi, df['y']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_lsi.to_csv('lsi.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 여기는 W2V model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5915, 624)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sentences = []\n",
    "for idx, el in enumerate(doc): #어근 분류한것\n",
    "# for idx, el in enumerate(comments): # 그냥 넣은것\n",
    "#     sentences.append(models.doc2vec.LabeledSentence(words=el, tags=[df['y'][idx]]))\n",
    "    sentences.append(models.doc2vec.LabeledSentence(words=el, tags=['r%d'%idx]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 train completed\n",
      "epoch: 1 train completed\n",
      "epoch: 2 train completed\n",
      "epoch: 3 train completed\n",
      "epoch: 4 train completed\n",
      "epoch: 5 train completed\n",
      "epoch: 6 train completed\n",
      "epoch: 7 train completed\n",
      "epoch: 8 train completed\n",
      "epoch: 9 train completed\n",
      "epoch: 10 train completed\n",
      "epoch: 11 train completed\n",
      "epoch: 12 train completed\n",
      "epoch: 13 train completed\n",
      "epoch: 14 train completed\n",
      "Wall time: 2min 35s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# doc2vec training session\n",
    "# 너무 sparse하면 또 학습이 잘 안됨 50~100정도가 적당...\n",
    "size=24\n",
    "model = models.Doc2Vec(size=size, window=7, min_count=1, workers=8,alpha=0.025, min_alpha=0.025)\n",
    "\n",
    "model.build_vocab(sentences) # 오로지 한번만 스트럭팅 가능\n",
    "# 너무 오래 트레이닝하면 오히려 벡터가 망가짐...??\n",
    "for epoch in range(15):\n",
    "    if epoch%1 ==0:\n",
    "        print('epoch:',epoch, 'train completed')\n",
    "    model.train(sentences, total_examples=model.corpus_count, epochs=model.iter)\n",
    "    model.alpha -= 0.002 # decrease the learning rate\n",
    "    model.min_alpha = model.alpha  # fix the learning rate, no decay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153790, 24)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = doc.reshape([-1,24])\n",
    "doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 이거는 문서 전체 평균내는거\n",
    "mtx = []\n",
    "for i in doc:\n",
    "    row = []\n",
    "    for j in i:\n",
    "        row.append(model.wv[j])\n",
    "    row = np.array(row)\n",
    "    row = row.mean(axis=0)\n",
    "    mtx.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx = np.array(mtx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(153790, 24)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mtx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mtx = mtx.reshape([-1,26*24])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w2v = pd.DataFrame(mtx, columns=['w2v%d'%idx for idx in range(mtx.shape[1])])\n",
    "df_w2v = pd.concat([df['macaddr'], df_w2v, df['y']], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_w2v.to_csv('w2v.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "여기는 3d CRNN용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc.shape\n",
    "doc2= doc.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = [model.wv[i] for i in doc2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc3 = np.array(doc3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3690960, 24)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3690960,)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = doc3.reshape(-1, 26, 24, 24)\n",
    "# doc4 = doc3.reshape(-1, 26*24*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5915, 26, 24, 24)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc4 = np.transpose(doc4, (0,2,3,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "doc4 = doc4.flatten()\n",
    "doc4 = doc4.reshape(-1, 24*24*26)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_w2v2 = pd.DataFrame(doc4, columns=['w2v%d'%idx for idx in range(doc4.shape[1])])\n",
    "df_w2v2 = pd.concat([df['macaddr'], df_w2v2, df['y']], axis=1)\n",
    "df_w2v2.to_csv('w2v_crnn.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
